#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import tensorflow as tf
from arch.layers import conv2d, max_pool, flatten, dense


def mnist_sequential(x):
    """Creates sequential convolutional neural network for MNIST. The network
        uses 2 convolutional+pooling layers to create the representation part
        of the network, and 2 fully-connected dense layers to create the
        classifier part. Dropout layer is used for regularization. The output
        probabilities are generated by a softmax function.
    Args:
        x: A tensor representing the input.
    Returns:
        A tuple containing the layers of the network graph and additional
        placeholders if any. Layers are represented as list of named tuples.
    """    
    
    layers = []
    variables = []

    # conv1
    conv1 = conv2d(x, size=5, n_filters=32, name="conv1")
    layers.append(("conv1", conv1))
            
    pool1 = max_pool(conv1, name="pool1")
    layers.append(("pool1", pool1))

    # conv2
    conv2 = conv2d(pool1, size=5, n_filters=64, name="conv2")
    layers.append(("conv2", conv2))
        
    pool2 = max_pool(conv2, name="pool2")
    layers.append(("pool2", pool2))

    # flatten
    flat = flatten(pool2, name="flatten")
    layers.append(("flatten", flat))

    # fc1
    fc1 = dense(flat, n_units=1024, name="fc1")
    layers.append(("fc1", fc1))
    
    # dropout
    training = tf.placeholder(tf.bool, name="training")
    dropout1 = tf.layers.dropout(fc1, rate=0.5, training=training, seed=42)
    layers.append(("dropout1", dropout1))
    variables.append(("training", training))
    
    # dense2
    fc2 = dense(dropout1, n_units=10, activation=None, name="fc2")
    layers.append(("fc2", fc2))
    
    prob = tf.nn.softmax(fc2, name="prob")
    layers.append(("prob", prob))
    
    return layers, variables
    